<p align="center">
  <img src="build/icon.png" alt="WhichClaw" width="120" />
</p>

<h1 align="center">WhichClaw</h1>

<p align="center">
  <strong>Visual AI Model Switching & Configuration Hub for Coding Tools</strong>
</p>

<p align="center">
  <a href="https://github.com/ebenxp707-boop/WhichClaw/releases">
    <img src="https://img.shields.io/github/v/release/ebenxp707-boop/WhichClaw?style=flat-square&color=00FF9D" alt="Release" />
  </a>
  <img src="https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-blue?style=flat-square" alt="Platform" />
  <img src="https://img.shields.io/github/license/ebenxp707-boop/WhichClaw?style=flat-square" alt="License" />
</p>

<p align="center">
  <a href="./README.md">English</a> Â·
  <a href="./docs/README.zh-CN.md">ç®€ä½“ä¸­æ–‡</a> Â·
  <a href="./docs/README.ja.md">æ—¥æœ¬èª</a> Â·
  <a href="./docs/README.ko.md">í•œêµ­ì–´</a>
</p>

---

## âœ¨ What is WhichClaw?

WhichClaw is a desktop application that provides a **visual, unified interface** for managing AI models across your coding tools. No more digging through config files or worrying about token usage â€” just point, click, and switch.

### The Problem

- ğŸ˜« Switching AI models in tools like OpenClaw requires editing config files manually
- ğŸ’¸ No visibility into token consumption across different tools
- ğŸ”„ Each tool has its own model configuration format
- ğŸ”‘ API keys scattered across multiple config files

### The Solution

WhichClaw acts as a **central control panel** for all your AI-powered coding tools:

- ğŸ¯ **One-Click Model Switching** â€” Visually switch AI models for any supported tool
- ğŸ“Š **Token Usage Monitoring** â€” Track consumption and costs in real-time
- ğŸ” **Secure Key Management** â€” Encrypted API key storage with hardware binding
- ğŸ–¥ï¸ **Local Model Support** â€” Run open-source models (Llama, Mistral) locally via llama.cpp
- ğŸ® **Built-in AI Playground** â€” Test models with interactive games like AI Reversi

## ğŸ–¼ï¸ Screenshots

<!-- Add screenshots here when available -->
<!-- ![Dashboard](docs/screenshots/dashboard.png) -->

## ğŸš€ Quick Start

### Download

Get the latest release for your platform:

| Platform | Download |
|----------|----------|
| Windows  | [WhichClaw-Setup.exe](https://github.com/ebenxp707-boop/WhichClaw/releases/latest) |
| macOS    | [WhichClaw.dmg](https://github.com/ebenxp707-boop/WhichClaw/releases/latest) |
| Linux    | [WhichClaw.AppImage](https://github.com/ebenxp707-boop/WhichClaw/releases/latest) |

### Linux Notes

```bash
chmod +x WhichClaw-*.AppImage
./WhichClaw-*.AppImage
```

> If you encounter FUSE errors: `sudo apt install libfuse2`

## ğŸ”§ Supported Tools

| Tool | Status | Model Switching | Protocol |
|------|--------|----------------|----------|
| OpenClaw | âœ… Supported | âœ… | OpenAI / Anthropic |
| Claude Code | âœ… Supported | âœ… | Anthropic |
| Cline | âœ… Supported | âœ… | OpenAI / Anthropic |
| Continue | âœ… Supported | âœ… | OpenAI |
| Aider | âœ… Supported | âœ… | OpenAI |
| OpenCode | âœ… Supported | âœ… | OpenAI |
| Codex | âœ… Supported | âœ… | OpenAI |
| Roo Code | ğŸ”œ Coming | â€” | â€” |

## ğŸ—ï¸ Tech Stack

- **Electron** â€” Cross-platform desktop framework
- **React + TypeScript** â€” UI framework
- **Tailwind CSS** â€” Styling
- **Vite** â€” Build tool
- **llama.cpp** â€” Local model inference

## ğŸ› ï¸ Development

```bash
# Install dependencies
npm install

# Start development server
npm run dev

# Build for production
npm run build
```

## ğŸ“„ License

[MIT](LICENSE)

---

<p align="center">
  Made with ğŸ’š by the WhichClaw Team
</p>
